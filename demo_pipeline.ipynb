{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üõ∞Ô∏è Methane Shadow Hunter - End-to-End Logic Demo\n",
                "This notebook demonstrates the core logic pipeline for detecting, attributing, and quantifying methane super-emitters, mapping them to oil & gas infrastructure, and generating LangChain-powered compliance audits."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Ensure the src/ folder is in path\n",
                "sys.path.insert(0, str(Path().resolve()))\n",
                "\n",
                "from src.config import config\n",
                "from src.data.sentinel5p import Sentinel5PClient\n",
                "from src.data.carbonmapper import CarbonMapperClient\n",
                "from src.data.infrastructure import InfrastructureDB\n",
                "from src.fusion.hotspot_detector import HotspotDetector\n",
                "from src.fusion.tasking_simulator import TaskingSimulator\n",
                "from src.fusion.spatial_join import SpatialJoiner\n",
                "from src.plume.inversion import PlumeInverter\n",
                "from src.plume.wind import WindField\n",
                "from src.agent.reporting_agent import ComplianceAuditAgent"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Data Ingestion: Coarse Sentinel-5P Hotspots\n",
                "First, we load the `India_Methane_Hotspots.csv` dataset, parsing the geometries and calculating baseline anomaly scores."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "s5p_client = Sentinel5PClient()\n",
                "hotspots_df = s5p_client.load_hotspots_csv()\n",
                "display(hotspots_df.head())\n",
                "\n",
                "print(\"\\nDataset Summary Stats:\")\n",
                "print(s5p_client.get_summary_stats())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Multi-Scale Data Fusion: Hotspot Detection & Tasking\n",
                "Filter standard methane anomalies from genuine \"Super-Emiters\" using a Sigma threshold.\n",
                "Then trigger a simulated high-res tasking request (e.g., GHGSat, Planet)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "detector = HotspotDetector(threshold_sigma=2.0)\n",
                "detected = detector.detect(hotspots_df)\n",
                "tasking_candidates = detector.get_tasking_candidates(detected)\n",
                "\n",
                "print(\"Detection Summary:\")\n",
                "print(detector.summary(detected))\n",
                "\n",
                "# Simulate tasking high-res satellites for top 5 candidates\n",
                "tasking = TaskingSimulator()\n",
                "requests = tasking.create_tasking_requests(tasking_candidates, max_requests=5)\n",
                "print(f\"\\nCreated {len(requests)} tasking requests. Example:\", requests[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. High-Res Plume Attribution (Spatial Join)\n",
                "Using CarbonMapper STAC AI to find high-resolution plumes and joined with local oil & gas infrastructure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cm_client = CarbonMapperClient()\n",
                "infra_db = InfrastructureDB()\n",
                "joiner = SpatialJoiner(radius_km=5.0)\n",
                "\n",
                "hotspot_coords = [(h.latitude, h.longitude) for h in tasking_candidates[:5]]\n",
                "plumes = cm_client.generate_synthetic_plumes(hotspot_coords) # Uses synthetic for offline demo\n",
                "\n",
                "facilities = infra_db.load_facilities()\n",
                "attributed = joiner.join(plumes, facilities)\n",
                "\n",
                "print(f\"Attributed {len(attributed)} plumes to infrastructure.\")\n",
                "if attributed:\n",
                "    print(\"\\nTop Attributed Emitter:\")\n",
                "    print(f\"Facility: {attributed[0].facility_name} ({attributed[0].operator})\")\n",
                "    print(f\"Distance: {attributed[0].pinpoint_accuracy_m}m\")\n",
                "    print(f\"Emission Rate: {attributed[0].emission_rate_kg_hr} kg/hr\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Plume Inversion Modeling (PyTorch)\n",
                "Using a differentiable Gaussian Plume Model to reverse-engineer the actual emission rate `Q` (kg/hr)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wind = WindField()\n",
                "inverter = PlumeInverter()\n",
                "\n",
                "if attributed:\n",
                "    attr = attributed[0]\n",
                "    wind_data = wind.get_wind(attr.plume_lat, attr.plume_lon)\n",
                "    \n",
                "    print(\"Running Plume Inversion Optimization in PyTorch...\")\n",
                "    true_Q_kg_s = attr.emission_rate_kg_hr / 3600\n",
                "    synth = inverter.create_synthetic_observation(\n",
                "        true_Q_kg_s=true_Q_kg_s, \n",
                "        wind_speed=wind_data.speed_ms,\n",
                "        stability_class=wind_data.stability_class\n",
                "    )\n",
                "    \n",
                "    result = inverter.invert(\n",
                "        observed_concentrations=synth[\"observed_concentrations\"],\n",
                "        receptor_x=synth[\"receptor_x\"],\n",
                "        receptor_y=synth[\"receptor_y\"],\n",
                "        receptor_z=synth[\"receptor_z\"],\n",
                "        wind_speed=wind_data.speed_ms,\n",
                "        initial_Q=0.01,\n",
                "        true_Q_kg_hr=synth[\"true_Q_kg_hr\"]\n",
                "    )\n",
                "    \n",
                "    print(f\"Target Emission:  {synth['true_Q_kg_hr']:.2f} kg/hr\")\n",
                "    print(f\"Estimated (Inv):  {result.estimated_Q_kg_hr:.2f} kg/hr\")\n",
                "    print(f\"Error Margin:     {result.error_pct}%\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Autonomous Reporting Agent (LangChain + Featherless AI)\n",
                "The data is passed to a Featherless AI LLM agent (OpenAI-compatible) to create a structured compliance audit."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "agent = ComplianceAuditAgent(\n",
                "    model=config.featherless_model,\n",
                "    api_key=config.featherless_api_key,\n",
                "    base_url=config.featherless_base_url,\n",
                ")\n",
                "\n",
                "if attributed:\n",
                "    report = agent.generate_report(attributed[0], plumes[0])\n",
                "    print(\"\\n================ AUDIT REPORT ================\")\n",
                "    print(report.report_markdown[:700] + \"\\n\\n[...Report Trimmed For Display...]\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
